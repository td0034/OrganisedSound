
Without quantitive taken into account:
{
4.X Qualitative findings: composing and interpreting intermedial relations under modality constraint

Across conditions, participants described compositional strategies that clustered into (i) density shaping (e.g., filling the grid then thinning it), (ii) arc/narrative forms (crescendo–chaos–release), (iii) loop-based structuring, (iv) harmony/scale manipulation (sometimes via colour similarity as a proxy), and (v) exploratory “A/B testing” of parameters. In the visual-only condition (A), participants often treated the panel as a dynamic visual field and composed by “covering the grid” or sculpting density over time. In the audio-only condition (B), strategies more often emphasised texture, pacing and repetition as a “container”, with looping described as a means of establishing predictability and avoiding collapse into noise. In the audiovisual condition (C), participants frequently reported combining what they had learned in the earlier blocks, but also noted that managing both modalities could either increase creative satisfaction (when a “co-creative” stance emerged) or increase perceived workload (when attempting to optimise sound and light simultaneously).

4.X.1 The reveal as a site of intermedial (re)binding

A recurring phenomenon was the “reveal” (replay with both modalities enabled after composing under constraint) functioning as a moment of retrospective binding: participants described surprise, delight, or a re-evaluation of what they believed they had controlled. Several accounts indicate that the coupled playback could feel more coherent than the compositional experience itself. For example, participants reported outcomes being “much better than I thought it would be” and that the sound/visual “fitted together” despite having “no idea how it would sound” while composing. Others described the reveal as disclosing latent structure: “the video review revealed more structures than I expected”, with visual patterns helping to “reveal the relationships between notes”. In the audio-only block in particular, multiple participants reported positive mismatch (“the revealed modality … went beyond my expectations”), suggesting that constraint can support a productive form of intermedial interference where the withheld modality is experienced as a meaningful addition rather than a competing stream.

4.X.2 Attentional hierarchy and “media equality” in practice

Participants repeatedly articulated an attentional hierarchy between modalities. Some explicitly reported that sound dominated their experience (“sound felt like a more dominant sensory driver”), or that audio needed to be removed before they could attend to the visual composition (“the audio had to be removed completely before I could prioritise the visual”). Others self-identified as more visually oriented and described greater controllability when composing visually, while finding audio-only “harder to control” despite later recognising more structure on replay. These accounts support the claim that “media equality” is not an intrinsic property of an audiovisual instrument; rather, it is negotiated through attention, familiarity, and the availability of stable reference cues (e.g., looped repetition, density baselines, colour–pitch mapping legibility).

4.X.3 Intermedial interference as cue conflict (temporal, density, and perceptual)

When interference was described as disruptive, it was frequently framed as a cue conflict: one modality implying causal or temporal relationships that the other did not support. The most concrete instance was a temporal mismatch between note duration and light persistence: participants noted that “light activity was misleading for tone length”, and that they “did not find much association between light duration and note duration”. A second recurrent mismatch concerned density: sparse visuals sometimes corresponded to “busy” sound, and conversely, visually active states could be perceived as less complex sonically than expected. Participants also flagged perceptual masking introduced by the chosen timbre: pure tones and octave stacking were described as collapsing multiple events into a single percept (“different octaves … sounded as one”), which undermined the ability to audit harmony and thereby weakened cross-modal predictability. Notably, some participants reported moving away from theory-driven expectations toward a more intuition-driven use of the coupled mapping (e.g., “started with theory then migrated to using the lights”), indicating that interference can prompt a shift in compositional stance.

4.X.4 Agency and co-creative negotiation with an autonomous substrate

Across conditions, participants framed their interaction with the system as a negotiation of agency rather than direct control. Several described pleasure in a hybrid of steerability and surprise (“control yet … play and surprise”), and one articulated the core agency ambiguity directly: “if I performed or the Tonnetz performed”. Others linked frustration to expectation and expertise (“frustration comes with expectation”), and characterised learning as being supported by low frustration and playful mindset. In audiovisual composition (C), some participants described a transition toward acceptance and collaboration with the instrument (“we (me and instrument) is the dyad”), which corresponded to higher creative satisfaction and reduced monitoring for mismatch during replay.

4.X.5 Participant-led design requirements and interpretability

Participants produced convergent, instrument-actionable requirements. These include: clearer loop behaviour and reset affordances; parameter units and more legible scaling (including counter-intuitive “rate” behaviour); reduced interface fragmentation (one page without scrolling); improved colour fidelity between controller and panel; richer articulation (ADSR/envelopes) and/or timbral complexity to improve event discriminability; alignment between audio note length and light persistence (or an intentional visual intensity decay to communicate note release); and ergonomic considerations such as panel viewing angle and more tactile input affordances. These design requirements are directly coupled to the interference and agency accounts above: where mapping legibility and temporal cues were ambiguous, participants described mismatch and reduced controllability; where cues supported stable reference (e.g., looping), participants described safety, predictability, and more intentional structuring.

(Optional closing sentence for the qualitative section)
Taken together, these accounts suggest that intermedial interference is experienced less as a binary of “aligned/misaligned” and more as a dynamic negotiation between cue reliability, attentional dominance, and the performer’s evolving causal model of the shared generative substrate.
}





with quantitative taken into account
{
4.X.X Condition preference and perceived intermediality

Across the merged dataset, the audiovisual condition (C) was most frequently preferred and most frequently described as intermedial in the end-of-session reflections. Eight of nine participants ranked C as their top condition, and seven of nine explicitly selected C as “most intermedial”. This convergence is notable because participants varied in musical experience and began the study in different block orders. In contrast, the audio-only condition (B) was most often identified as producing the “biggest mismatch”, despite often yielding satisfying outcomes on replay. Taken together, these responses suggest that perceived intermediality is not simply an abstract judgement of mapping accuracy; it is also an experiential judgement about how effectively the coupled system supports intention formation, monitoring, and retrospective sense-making.

4.X.X Audio-only as the primary mismatch condition: monitoring, uncertainty, and strategy shift

The most consistent qualitative–quantitative alignment in the merged dataset is the concentration of “biggest mismatch” selections in the audio-only condition (6/9). Participants repeatedly framed audio-only as a loss of state visibility—a difficulty in knowing what the system is currently doing and how their interventions have changed it. This tended to trigger a strategy shift: rather than composing “toward” a planned audiovisual outcome, participants described prioritising texture, repetition, pacing, and risk management (e.g., keeping things “safe” via looping and sparseness) while accepting that the withheld visual field would later reveal unanticipated structures. The audio-only condition therefore functions as both a constraint and a stress test for the instrument’s interpretability: it exposes how much participants rely on visual feedback for causal inference and for maintaining a stable internal model during generative interaction.

4.X.X Positive mismatch: withheld modality as reward and calibration signal

Although mismatch was most frequently attributed to audio-only, the qualitative accounts indicate that mismatch is not uniformly negative. Several participants described the withheld modality on replay as unexpectedly “beautiful” or more coherent than anticipated, and one participant explicitly framed the biggest mismatch as positive. In these cases, mismatch appears to operate as a calibration signal: the replay reveals latent regularities in the shared generative substrate that were not perceptually available during constrained performance. This supports treating “interference” as valenced: cue conflict can be disruptive when it blocks prediction and control, but it can also be productive when it reveals structure and expands the performer’s understanding of the system’s audiovisual affordances.

4.X.X Expertise and interpretive stance: “light accompanies sound” versus “sound reveals structure”

With merged background metadata, you can now state (carefully) that interpretive stance varies with experience. Participants with little or no music theory reported that the visual modality helped them perceive structure and relationships (“the visual patterns help reveal the relationships between notes”), and they frequently framed the replay as evidence of musical “merit” emerging beyond their intentions. By contrast, at least one highly experienced participant described the audiovisual relation in a more conventional hierarchy (“light accompanying sound”), while still valuing cross-modal association as the primary satisfaction driver. Rather than implying a simple novice–expert split, the data supports a framing in terms of which modality participants treat as primary evidence for evaluating and steering the system.

4.X.X Parameter semantics and interface legibility as drivers of perceived control

The merged “session notes” and “one change” responses make the interpretability issue concrete. Participants repeatedly identified interface semantics as limiting their ability to form stable causal expectations (e.g., counter-intuitive rate mapping; ambiguous loop behaviour; missing units; need for reset/presets; colour similarity on the controller; mismatch between note length and light persistence). These concerns recur alongside agency language (“less in control”, “not doing what I want”) and alongside mismatch selections. This supports a direct claim that some “intermedial interference” effects are not purely perceptual: they also arise from the transparency of system controls and from the reliability of cues (temporal, chromatic, and rhythmic) required for iterative prediction–action–evaluation cycles.

4.X.X Reproducibility and authorship: composition as exploration of a shared autonomous process

A subtle but valuable theme becomes clearer in the merged set: several participants describe outcomes they enjoyed but could not reproduce (“don’t think I could reproduce it ever as it’s not in my head”), and they explicitly question authorship (“if I performed or the Tonnetz performed”). This sits alongside descriptions of play, surprise, and acceptance, and suggests that participants treat the system less as a deterministic instrument and more as an autonomous collaborator whose behaviour must be negotiated rather than commanded. In this framing, “intermedial composition” is not only the production of an artefact; it is the cultivation of a working relationship with a shared generative substrate—one that is sometimes more legible in replay than in action.
}



Participants and completeness (Table 1)

Nine participants completed all three blocks (N=9; 27/27 blocks; no missing quantitative items). All sessions were solo. Participants spanned multiple age ranges (including one 65+), and musical experience ranged from none to advanced/professional; two participants reported high music/theory familiarity and one reported colour deficiency (red–green). See Table 1 for overview.

Preferences and “most intermedial” judgments (Fig 1)

Participants overwhelmingly preferred the audio–visual condition (C). Eight of nine participants ranked C as their top condition, with one participant preferring B and none preferring A. When asked which condition felt “most intermedial”, seven participants selected C and one selected B (no participants selected A), with the remaining response recorded as unsure depending on coding. In contrast, the largest expectation mismatch was most frequently reported in B (6/9), followed by A (2/9) and C (1/9). These distributions are summarised in Fig1_outcomes_counts.

Perceived steerability depends on available modality (Fig 2; Table 2)

Perceived ability to steer the system toward an intention (A3) was highest when composing with visual access (A: median 6.00 [4.00, 6.00]), lowest when composing audio-only (B: 4.00 [3.00, 5.00]), and intermediate for audio–visual (C: 5.00 [5.00, 5.00]). This paired pattern is shown in Fig2_paired_control_A3 and aligns with participants’ qualitative reports that visual feedback supported agency and learning-by-adjustment, while the audio-only constraint could feel like “something missing” during performance.

Notably, outcome satisfaction (A1) did not track steerability directly. Satisfaction was lowest in A (5.00 [4.00, 6.00]) and higher in both B (6.00 [4.00, 6.00]) and C (6.00 [5.00, 6.00]) (Table 2). This supports the qualitative observation that even when audio-only performance felt harder to control, the subsequent reveal could be experienced as structured and aesthetically rewarding.

Intermedial coherence is strongest after audio-only and audio–visual composition (Fig 3; Table 2)

Ratings for “two views of the same underlying process” (B1) were markedly higher in B and C than in A (A: 4.00 [3.00, 6.00]; B: 6.00 [6.00, 7.00]; C: 6.00 [6.00, 6.00]) (Table 2). In other words, participants more strongly perceived intermedial coupling when the composition stage either foregrounded sound (B) or integrated both modalities (C), whereas composing from visuals alone produced weaker “same process” judgments on reveal. This pattern is captured by the paired intermediality summary in Fig3_paired_intermediality_index, and it dovetails with qualitative accounts of (i) surprise and reinterpretation on reveal, and (ii) difficulties predicting sonic complexity from visual density in the visual-only block for some participants.

Overload and autonomy (Table 2; optional Fig 4)

Perceptual overload (B6) remained low across conditions (A: 2.00 [1.00, 2.00]; B: 2.00 [2.00, 3.00]; C: 2.00 [2.00, 2.00]). Although participants sometimes described moments of chaos or intensity qualitatively, these did not translate into consistently high overload ratings at the group level. Perceived system autonomy (B10) was moderate in A and B (both 4.00 [3.00, 5.00]) and slightly higher in C (5.00 [2.00, 5.00]), consistent with qualitative language of “collaboration” when both modalities were available.

(If you keep Fig4_paired_overload_B6, this paragraph becomes more convincing as a “negative finding”: overload is not the main mechanism; mismatch/control/reinterpretation is.)

Parameter strategy differs by condition (Fig 6; counts table)

Participants’ self-reported “most influential parameters” show a stable core and a modality-dependent shift. Rate was the dominant control across all conditions (A: 8 selections; B: 7; C: 6), consistent with participants using global tempo/dynamism to shape arcs and transitions. Scale shows the clearest modality dependence: it was cited far more often when sound was available during composition (B: 7; C: 8) than in visual-only composition (A: 3), suggesting that harmonic/tonal considerations become salient when participants are actively managing auditory outcomes. Other structural parameters (Life Length; neighbour and population thresholds) were cited at moderate frequency across conditions, supporting the qualitative framing of “constraint tuning” and “finding stable states” as part of the exploration. These distributions are shown in Fig6_param_influence_by_condition.